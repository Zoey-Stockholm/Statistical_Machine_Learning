{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "import graphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Tree-Based-Methods\">Tree-Based Methods<a class=\"anchor-link\" href=\"#Tree-Based-Methods\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"8.1-Classification-tree\">8.1 Classification tree<a class=\"anchor-link\" href=\"#8.1-Classification-tree\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>This problem involves the <code>OJ</code> dataset (<code>data/oj.csv</code>)<br/>\n",
    "<strong>Orange Juice Data</strong></p>\n",
    "<p>The data contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. A number of characteristics of the customer and product are recorded.</p>\n",
    "<p>A data frame with 1070 observations on the following 18 variables:</p>\n",
    "<p><code>Purchase</code> :A factor with levels CH and MM indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice<br/>\n",
    "<code>WeekofPurchase</code>: Week of purchase<br/>\n",
    "<code>StoreID</code>: Store ID<br/>\n",
    "<code>PriceCH</code>: Price charged for CH<br/>\n",
    "<code>PriceMM</code>: Price charged for MM<br/>\n",
    "<code>DiscCH</code>: Discount offered for CH\n",
    "<code>DiscMM</code>: Discount offered for MM<br/>\n",
    "<code>SpecialCH</code>: Indicator of special on CH<br/>\n",
    "<code>SpecialMM</code>: Indicator of special on MM<br/>\n",
    "<code>LoyalCH</code>: Customer brand loyalty for CH<br/>\n",
    "<code>SalePriceMM</code>: Sale price for MM<br/>\n",
    "<code>SalePriceCH</code>: Sale price for CH<br/>\n",
    "<code>PriceDiff</code>: Sale price of MM less sale price of CH<br/>\n",
    "<code>Store7</code>: A factor with levels No and Yes indicating whether the sale is at Store 7<br/>\n",
    "<code>PctDiscMM</code>: Percentage discount for MM<br/>\n",
    "<code>PctDiscCH</code>: Percentage discount for CH<br/>\n",
    "<code>ListPriceDiff</code>: List price of MM less list price of CH<br/>\n",
    "<code>STORE</code>: Which of 5 possible stores the sale occured at</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"a)\">a)<a class=\"anchor-link\" href=\"#a)\">¶</a></h3><p>Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "#OJ = pd.read_csv('data/OJ.csv')\n",
    "OJ = pd.read_csv('https://uu-sml.github.io/course-sml-public/data/oj.csv')\n",
    "\n",
    "# sampling indices for training\n",
    "trainIndex = np.random.choice(OJ.shape[0], size=800, replace=False)\n",
    "train = OJ.iloc[trainIndex]                     # training set\n",
    "test = OJ.iloc[~OJ.index.isin(trainIndex)]      # test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Purchase        1070 non-null   object \n",
      " 1   WeekofPurchase  1070 non-null   int64  \n",
      " 2   StoreID         1070 non-null   int64  \n",
      " 3   PriceCH         1070 non-null   float64\n",
      " 4   PriceMM         1070 non-null   float64\n",
      " 5   DiscCH          1070 non-null   float64\n",
      " 6   DiscMM          1070 non-null   float64\n",
      " 7   SpecialCH       1070 non-null   int64  \n",
      " 8   SpecialMM       1070 non-null   int64  \n",
      " 9   LoyalCH         1070 non-null   float64\n",
      " 10  SalePriceMM     1070 non-null   float64\n",
      " 11  SalePriceCH     1070 non-null   float64\n",
      " 12  PriceDiff       1070 non-null   float64\n",
      " 13  Store7          1070 non-null   object \n",
      " 14  PctDiscMM       1070 non-null   float64\n",
      " 15  PctDiscCH       1070 non-null   float64\n",
      " 16  ListPriceDiff   1070 non-null   float64\n",
      " 17  STORE           1070 non-null   int64  \n",
      "dtypes: float64(11), int64(5), object(2)\n",
      "memory usage: 150.6+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OJ.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"b)\">b)<a class=\"anchor-link\" href=\"#b)\">¶</a></h3><p>Learn a classification tree from the training data using the function <code>sklearn.tree.DecisionTreeClassifier()</code>, with\n",
    "<code>Purchase</code> as the output and the other variables as inputs. Don't forget to handle qulitative variables correctly. To avoid severe overfit, you have to add some constraints to the tree, using, e.g., a maximum depth of 2 (<code>max_depth=2</code>).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = train.drop(columns=['Purchase'])\n",
    "# Need to transform the qualitative variables to dummy variables\n",
    "X_train = pd.get_dummies(X_train, columns=['Store7'])\n",
    "y_train = train['Purchase']\n",
    "model = tree.DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X=X_train, y=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"c)\">c)<a class=\"anchor-link\" href=\"#c)\">¶</a></h3><p>Use <code>sklearn.tree.export_graphviz()</code>and the <code>Python</code> module <code>graphviz</code> to visualize the tree and interpret the result. How many terminal nodes does the tree have? Pick one of the terminal nodes, and interpret the information displayed. Type <code>OJ.info()</code> to get information about all input variables in the data set.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"650pt\" height=\"322pt\"\n",
       " viewBox=\"0.00 0.00 650.00 321.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 317.5)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-317.5 646,-317.5 646,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f6d5bc\" stroke=\"black\" d=\"M382,-313.5C382,-313.5 259,-313.5 259,-313.5 253,-313.5 247,-307.5 247,-301.5 247,-301.5 247,-242.5 247,-242.5 247,-236.5 253,-230.5 259,-230.5 259,-230.5 382,-230.5 382,-230.5 388,-230.5 394,-236.5 394,-242.5 394,-242.5 394,-301.5 394,-301.5 394,-307.5 388,-313.5 382,-313.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-298.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LoyalCH &lt;= 0.482</text>\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.479</text>\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.601, 0.399]</text>\n",
       "<text text-anchor=\"middle\" x=\"320.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = CH</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#6fb8ec\" stroke=\"black\" d=\"M300,-194.5C300,-194.5 177,-194.5 177,-194.5 171,-194.5 165,-188.5 165,-182.5 165,-182.5 165,-123.5 165,-123.5 165,-117.5 171,-111.5 177,-111.5 177,-111.5 300,-111.5 300,-111.5 306,-111.5 312,-117.5 312,-123.5 312,-123.5 312,-182.5 312,-182.5 312,-188.5 306,-194.5 300,-194.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-179.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">PriceDiff &lt;= 0.31</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.338</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.215, 0.785]</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = MM</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.05,-230.41C285.82,-221.51 279.16,-212.01 272.72,-202.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.5,-200.7 266.9,-194.52 269.77,-204.72 275.5,-200.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"262.57\" y=\"-215.44\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#ea9b62\" stroke=\"black\" d=\"M465,-194.5C465,-194.5 342,-194.5 342,-194.5 336,-194.5 330,-188.5 330,-182.5 330,-182.5 330,-123.5 330,-123.5 330,-117.5 336,-111.5 342,-111.5 342,-111.5 465,-111.5 465,-111.5 471,-111.5 477,-117.5 477,-123.5 477,-123.5 477,-182.5 477,-182.5 477,-188.5 471,-194.5 465,-194.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-179.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LoyalCH &lt;= 0.765</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.283</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 62.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.829, 0.171]</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = CH</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.3,-230.41C355.61,-221.51 362.35,-212.01 368.86,-202.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.82,-204.7 374.75,-194.52 366.11,-200.65 371.82,-204.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.94\" y=\"-215.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#5eafea\" stroke=\"black\" d=\"M135,-68C135,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 135,0 135,0 141,0 147,-6 147,-12 147,-12 147,-56 147,-56 147,-62 141,-68 135,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.266</text>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.158, 0.842]</text>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = MM</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.25,-111.41C164.14,-99.27 145.41,-85.99 128.45,-73.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.46,-71.1 120.27,-68.17 126.41,-76.81 130.46,-71.1\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#cee6f8\" stroke=\"black\" d=\"M300,-68C300,-68 177,-68 177,-68 171,-68 165,-62 165,-56 165,-56 165,-12 165,-12 165,-6 171,0 177,0 177,0 300,0 300,0 306,0 312,-6 312,-12 312,-12 312,-56 312,-56 312,-62 306,-68 300,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.429, 0.571]</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = MM</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.5,-111.41C238.5,-100.7 238.5,-89.12 238.5,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242,-78.17 238.5,-68.17 235,-78.17 242,-78.17\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#f1bb94\" stroke=\"black\" d=\"M465,-68C465,-68 342,-68 342,-68 336,-68 330,-62 330,-56 330,-56 330,-12 330,-12 330,-6 336,0 342,0 342,0 465,0 465,0 471,0 477,-6 477,-12 477,-12 477,-56 477,-56 477,-62 471,-68 465,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.432</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.685, 0.315]</text>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = CH</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.5,-111.41C403.5,-100.7 403.5,-89.12 403.5,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407,-78.17 403.5,-68.17 400,-78.17 407,-78.17\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e68641\" stroke=\"black\" d=\"M630,-68C630,-68 507,-68 507,-68 501,-68 495,-62 495,-56 495,-56 495,-12 495,-12 495,-6 501,0 507,0 507,0 630,0 630,0 636,0 642,-6 642,-12 642,-12 642,-56 642,-56 642,-62 636,-68 630,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.073</text>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32.8%</text>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.962, 0.038]</text>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = CH</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M460.75,-111.41C477.86,-99.27 496.59,-85.99 513.55,-73.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"515.59,-76.81 521.73,-68.17 511.54,-71.1 515.59,-76.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11af8de90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dot_data = tree.export_graphviz(model, out_file=None, feature_names = X_train.columns,\n",
    "                                class_names = model.classes_, filled=True, rounded=True, \n",
    "                                leaves_parallel=True, proportion=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"d)\">d)<a class=\"anchor-link\" href=\"#d)\">¶</a></h3><p>Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test error rate?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate is 0.80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Purchase</th>\n",
       "      <th>CH</th>\n",
       "      <th>MM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>142</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MM</th>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Purchase   CH  MM\n",
       "row_0            \n",
       "CH        142  24\n",
       "MM         30  74"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test = test.drop(columns=['Purchase'])\n",
    "X_test = pd.get_dummies(X_test, columns=['Store7'])\n",
    "y_test = test['Purchase']\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy rate is %.2f' % np.mean(y_predict == y_test))\n",
    "pd.crosstab(y_predict, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"e)\">e)<a class=\"anchor-link\" href=\"#e)\">¶</a></h3><p>Explore the different parameters you can pass to the tree command, such as <code>splitter</code>, <code>min_samples_split</code>, <code>min_samples_leaf</code>, <code>min_impurity_split</code> etc.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"8.2-Random-Forest\">8.2 Random Forest<a class=\"anchor-link\" href=\"#8.2-Random-Forest\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In this exercise we will use the email-spam data that has been presented in a couple of lectures. Go to the URL\n",
    "<a href=\"http://archive.ics.uci.edu/ml/datasets/Spambase\">http://archive.ics.uci.edu/ml/datasets/Spambase</a> for more information about the data.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"a)\">a)<a class=\"anchor-link\" href=\"#a)\">¶</a></h3><p>Load the dataset <code>data/email.csv</code></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url = 'data/email.csv'\n",
    "url = 'https://uu-sml.github.io/course-sml-public/data/email.csv'\n",
    "email = pd.read_csv(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(b)\">(b)<a class=\"anchor-link\" href=\"#(b)\">¶</a></h3><p>Create a training set containing a random sample of $75\\%$ of the observations, and a test set containing the remaining observations.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "trainIndex = np.random.choice(email.shape[0],size=int(len(email)*.75),replace=False)\n",
    "train = email.iloc[trainIndex]                     # training set\n",
    "test = email.iloc[~email.index.isin(trainIndex)]      # test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(c)\">(c)<a class=\"anchor-link\" href=\"#(c)\">¶</a></h3><p>Fit a classification tree with <code>Class</code> as output. Compute the test error.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train.copy().drop(columns=['Class'])\n",
    "y_train = train['Class']\n",
    "X_test = test.copy().drop(columns=['Class'])\n",
    "y_test = test['Class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate is 0.111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tree.DecisionTreeClassifier(max_leaf_nodes=5)\n",
    "model.fit(X=X_train, y=y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Test error rate is %.3f' % np.mean(y_predict != y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(d)\">(d)<a class=\"anchor-link\" href=\"#(d)\">¶</a></h3><p>Use the bagging approach to learn a classifier <code>sklearn.ensemble.BaggingClassifier()</code>. What test error do you get?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.063\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "error = np.mean(model.predict(X_test) != y_test)\n",
    "print('Test error: %.3f' % error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(e)\">(e)<a class=\"anchor-link\" href=\"#(e)\">¶</a></h3><p>Learn a random forest classifier using the function <code>sklearn.ensemble.RandomForestClassifier()</code>. What test error do you get?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "error = np.mean(model.predict(X_test) != y_test)\n",
    "print('Test error: %.3f' % error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"8.3-Bootstrap\">8.3 Bootstrap<a class=\"anchor-link\" href=\"#8.3-Bootstrap\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The bootstrap method has been introduced to reduce the variance in decision trees. However, the bootstrap method is widely applicable in other context as well, for example to estimate the variance in a parameter (cf. bias-variance tradeoff).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(a)\">(a)<a class=\"anchor-link\" href=\"#(a)\">¶</a></h3><p>Generate $n = 100$ samples $\\{y_i\\}_{i=1}^n$ from $\\mathcal{N}(4, 1^2)$.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "n = 100\n",
    "y = np.random.normal(4, 1, n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(b)\">(b)<a class=\"anchor-link\" href=\"#(b)\">¶</a></h3><p>We want to lean a model $y = \\theta_0 + \\epsilon$ (with $\\mathbb{E}[\\epsilon]=0$) from the data $\\{y_i\\}_{n=1}^n$. Estimate $\\theta_0$ with least squares, i.e. $\\hat{\\theta}_0 = \\frac{1}{n}\\sum_{i=1}^n y_i$.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.059808015534485"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "theta_0 = np.mean(y)\n",
    "theta_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(c)\">(c)<a class=\"anchor-link\" href=\"#(c)\">¶</a></h3><p>To estimate the variance in $\\hat{\\theta}_0$, $\\operatorname{Var}[\\hat{\\theta}_0]$ (a possible ‘quality measure’ of an estimator), repeat (a)-(b) $1000$ times to get $1000$ estimates of $\\theta_0$, which we call $\\hat{\\theta}_0^1, ..., \\hat{\\theta}_0^{1000}$. Plot a histogram over the estimates $\\hat{\\theta}_0^1, ..., \\hat{\\theta}_0^{1000}$.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "theta = []\n",
    "for i in range(1000):\n",
    "    theta.append(np.mean(np.random.normal(4, 1, n)))\n",
    "\n",
    "plt.hist(theta, bins=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In practice we only have access to $\\{y_i\\}_{n=1}^n$ $(n = 100)$ and cannot estimate $\\hat{\\theta}_0^1, ..., \\hat{\\theta}_0^{1000}$ by generating new data. However, with the bootstrap method we can obtain ‘new’ data sets by sampling from the original data set $\\{y_i\\}_{n=1}^n$.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(d)\">(d)<a class=\"anchor-link\" href=\"#(d)\">¶</a></h3><p>Sample $n$ indices $\\{i_1, i_2, ... , i_n\\}$ with replacement from the set $\\{0, 1, ... , n-1\\}$ using the function <code>numpy.random.choice()</code>. Note that some indices will appear multiple times and some will not appear at all.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 91, 78, 64, 51, 12, 89,  8, 33, 70, 35, 74, 84, 91, 74, 78, 75,\n",
       "       80, 40, 35, 97, 56, 16, 38, 86, 80, 98, 63, 11, 53, 32, 30, 75, 44,\n",
       "        7, 41, 97, 77, 60, 36, 63, 27, 61, 57, 66, 66, 48,  2, 25, 93, 56,\n",
       "       78, 33, 71, 64, 14, 68, 25, 28, 26, 76, 22, 30, 23, 51, 16, 24, 27,\n",
       "       74, 66, 80, 91, 43, 37,  6, 97, 91,  4, 83, 94, 62, 71,  1, 28, 64,\n",
       "       45, 19,  0, 72, 11, 86, 59, 90, 41, 13, 78, 25, 30, 48, 28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "indices = np.random.choice(np.arange(100), size=n, replace=True)\n",
    "indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(e)\">(e)<a class=\"anchor-link\" href=\"#(e)\">¶</a></h3><p>Generate a ‘new’ data set $\\{y_j\\}_{j=1}^n$ based on the indices generated in (d) and estimate $\\hat{\\mu}$ from this data set.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_new = y[indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"(f)\">(f)<a class=\"anchor-link\" href=\"#(f)\">¶</a></h3><p>Repeat (d)-(e) $1000$ times to get $1000$ estimates of $\\hat{\\mu}$, which we call $\\hat{\\mu}_1^*, ..., \\hat{\\mu}_{1000}^*$. Plot a histogram over the estimates $\\hat{\\mu}_1^*, ..., \\hat{\\mu}_{1000}^*$ and compare with the estimate achieved in (c).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mu = []\n",
    "for i in range(1000):\n",
    "    y_new = np.random.choice(y, size=n, replace=True)\n",
    "    mu.append(np.mean(y_new))\n",
    "\n",
    "plt.hist(mu, bins=14)\n",
    "plt.show()\n",
    "\n",
    "# The distribution of the estimates very similar to the first histogram,\n",
    "# but centered around $4.04$ which was the mean of this data set. Consequently,\n",
    "# we got a fairly accurate estimate of the uncertainity of the estimate without\n",
    "# generating new data. For a linear estimator like this one, the uncertainity \n",
    "# can be computed analytically (try to do that!), but in many nonlinear cases,\n",
    "# this is not tractable or even possible. Then, the bootstrap method is very\n",
    "# powerful.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
